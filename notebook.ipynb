{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715124e4",
   "metadata": {},
   "source": [
    "# MediSync FL India - Data Processing and ML Notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52988555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import hashlib\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0dd411",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FORMAT = '%(asctime)s | %(levelname)-7s | %(message)s'\n",
    "DATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "logger = logging.getLogger('medisync')\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.handlers.clear()\n",
    "logger.propagate = False\n",
    "\n",
    "formatter = logging.Formatter(LOG_FORMAT, datefmt=DATE_FORMAT)\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "def setup_file_logging(log_dir: Path):\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    log_path = log_dir / 'training.log'\n",
    "    file_handler = logging.FileHandler(log_path)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    for handler in list(logger.handlers):\n",
    "        if isinstance(handler, logging.FileHandler):\n",
    "            logger.removeHandler(handler)\n",
    "            handler.close()\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.info(f'Logging to {log_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31087de",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "logger.info(f'Random seed set to {SEED}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381451b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path('.').resolve()\n",
    "DATA_ROOT = PROJECT_ROOT / 'dataset'\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / 'models'\n",
    "ARTIFACTS_ROOT = PROJECT_ROOT / 'artifacts'\n",
    "LOGS_ROOT = PROJECT_ROOT / 'logs'\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ARTIFACTS_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "LOGS_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_next_run_dir(root: Path):\n",
    "    runs = []\n",
    "    for item in root.iterdir():\n",
    "        if item.is_dir() and item.name.startswith('run-'):\n",
    "            suffix = item.name[4:]\n",
    "            if suffix.isdigit():\n",
    "                runs.append(int(suffix))\n",
    "    next_id = max(runs, default=0) + 1\n",
    "    return root / f'run-{next_id:03d}'\n",
    "\n",
    "RUN_DIR = get_next_run_dir(ARTIFACTS_ROOT)\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CACHE_DIR = RUN_DIR\n",
    "RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "LOG_RUN_DIR = LOGS_ROOT / RUN_TIMESTAMP\n",
    "setup_file_logging(LOG_RUN_DIR)\n",
    "\n",
    "logger.info(f'Artifacts run dir: {RUN_DIR}')\n",
    "logger.info(f'Log run dir: {LOG_RUN_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP = {\n",
    "    'glioma': 0,\n",
    "    'meningioma': 1,\n",
    "    'pituitary': 2,\n",
    "    'notumor': 3\n",
    "}\n",
    "\n",
    "IDX_TO_LABEL = {v: k for k, v in LABEL_MAP.items()}\n",
    "\n",
    "logger.info(f'Label map initialized with {len(LABEL_MAP)} classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511472f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOSPITAL_CONFIGS = {\n",
    "    'AIIMS Delhi': {\n",
    "        'dataset_id': 'dataset-1',\n",
    "        'specialty': 'Adult Neuro-Oncology',\n",
    "        'location': [28.5672, 77.2100]\n",
    "    },\n",
    "    'NIMHANS Bengaluru': {\n",
    "        'dataset_id': 'dataset-2',\n",
    "        'specialty': 'Neuro Specialty',\n",
    "        'location': [12.9442, 77.5966]\n",
    "    },\n",
    "    'Tata Memorial Mumbai': {\n",
    "        'dataset_id': 'dataset-3',\n",
    "        'specialty': 'Oncology Referral',\n",
    "        'location': [19.0049, 72.8414]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\n",
    "    {\n",
    "        'id': 'dataset-1',\n",
    "        'hospital': 'AIIMS Delhi',\n",
    "        'path': DATA_ROOT / 'dataset-1',\n",
    "        'class_map': {\n",
    "            'glioma': 'glioma',\n",
    "            'meningioma': 'meningioma',\n",
    "            'pituitary': 'pituitary',\n",
    "            'notumor': 'notumor'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'id': 'dataset-2',\n",
    "        'hospital': 'NIMHANS Bengaluru',\n",
    "        'path': DATA_ROOT / 'dataset-2',\n",
    "        'class_map': {\n",
    "            'glioma': 'glioma',\n",
    "            'meningioma': 'meningioma',\n",
    "            'pituitary tumor': 'pituitary'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'id': 'dataset-3',\n",
    "        'hospital': 'Tata Memorial Mumbai',\n",
    "        'path': DATA_ROOT / 'dataset-3' / 'Brain_Cancer raw MRI data' / 'Brain_Cancer',\n",
    "        'class_map': {\n",
    "            'brain_glioma': 'glioma',\n",
    "            'brain_menin': 'meningioma',\n",
    "            'brain_tumor': 'pituitary'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "logger.info(f'Configured {len(DATASETS)} hospital datasets')\n",
    "for ds in DATASETS:\n",
    "    logger.info(f\"  - {ds['hospital']}: {ds['path']}\")\n",
    "\n",
    "CACHE_INDEX_FILE = RUN_DIR / 'dataset_index.json'\n",
    "CACHE_SPLITS_FILE = RUN_DIR / 'dataset_splits.json'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f'Using device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d393e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_EXTS = {'.jpg', '.jpeg', '.png'}\n",
    "\n",
    "def normalize_folder_name(name):\n",
    "    cleaned = name.strip().lower()\n",
    "    cleaned = cleaned.replace('_', ' ').replace('-', ' ')\n",
    "    cleaned = ' '.join(cleaned.split())\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c75bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_label(folder_name, class_map):\n",
    "    normalized_map = {normalize_folder_name(k): v for k, v in class_map.items()}\n",
    "    normalized = normalize_folder_name(folder_name)\n",
    "\n",
    "    if normalized in normalized_map:\n",
    "        return normalized_map[normalized], normalized\n",
    "\n",
    "    collapsed = normalized.replace(' ', '')\n",
    "    candidates = [\n",
    "        key for key in normalized_map\n",
    "        if key.replace(' ', '') == collapsed\n",
    "    ]\n",
    "    if len(candidates) == 1:\n",
    "        return normalized_map[candidates[0]], candidates[0]\n",
    "\n",
    "    candidates = [key for key in normalized_map if key in normalized or normalized in key]\n",
    "    if len(candidates) == 1:\n",
    "        return normalized_map[candidates[0]], candidates[0]\n",
    "\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_dataset_structure(dataset_config):\n",
    "    base_path = dataset_config['path']\n",
    "    summary = {\n",
    "        'dataset_id': dataset_config['id'],\n",
    "        'hospital': dataset_config['hospital'],\n",
    "        'base_path': base_path.as_posix(),\n",
    "        'exists': base_path.exists(),\n",
    "        'subdirs': [],\n",
    "        'total_images': 0,\n",
    "        'images_by_dir': {}\n",
    "    }\n",
    "\n",
    "    if not base_path.exists():\n",
    "        logger.error(f\"Dataset path missing: {base_path}\")\n",
    "        return summary\n",
    "\n",
    "    subdirs = [d for d in base_path.iterdir() if d.is_dir()]\n",
    "    summary['subdirs'] = [d.name for d in subdirs]\n",
    "    if not subdirs:\n",
    "        logger.error(f\"No class folders found in {base_path}\")\n",
    "        return summary\n",
    "\n",
    "    for class_dir in subdirs:\n",
    "        count = 0\n",
    "        for file_path in class_dir.rglob('*'):\n",
    "            if file_path.suffix.lower() in IMAGE_EXTS:\n",
    "                count += 1\n",
    "        summary['images_by_dir'][class_dir.name] = count\n",
    "        summary['total_images'] += count\n",
    "\n",
    "    logger.info(f\"Audit {summary['hospital']}: {summary['total_images']} images across {len(subdirs)} folders\")\n",
    "    logger.info(f\"  Folders: {summary['subdirs']}\")\n",
    "    logger.info(f\"  Images by folder: {summary['images_by_dir']}\")\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_images(dataset_config):\n",
    "    \"\"\"Collect all images from a dataset directory.\"\"\"\n",
    "    base_path = dataset_config['path']\n",
    "    class_map = dataset_config['class_map']\n",
    "    items = []\n",
    "    matched_folders = set()\n",
    "    unmatched_folders = []\n",
    "\n",
    "    if not base_path.exists():\n",
    "        logger.warning(f\"Dataset path does not exist: {base_path}\")\n",
    "        return items, {\n",
    "            'matched_folders': [],\n",
    "            'unmatched_folders': [],\n",
    "            'images_found': 0\n",
    "        }\n",
    "\n",
    "    for class_dir in base_path.iterdir():\n",
    "        if not class_dir.is_dir():\n",
    "            continue\n",
    "        label, matched_key = resolve_label(class_dir.name, class_map)\n",
    "        if label is None:\n",
    "            unmatched_folders.append(class_dir.name)\n",
    "            logger.warning(f\"Unmapped class folder: {class_dir.name}\")\n",
    "            continue\n",
    "        matched_folders.add(class_dir.name)\n",
    "        count = 0\n",
    "        for file_path in class_dir.rglob('*'):\n",
    "            if file_path.suffix.lower() in IMAGE_EXTS:\n",
    "                items.append({\n",
    "                    'path': file_path.as_posix(),\n",
    "                    'label': label,\n",
    "                    'dataset_id': dataset_config['id'],\n",
    "                    'hospital': dataset_config['hospital']\n",
    "                })\n",
    "                count += 1\n",
    "        logger.info(f\"  {dataset_config['hospital']} - {label}: {count} images\")\n",
    "\n",
    "    return items, {\n",
    "        'matched_folders': sorted(matched_folders),\n",
    "        'unmatched_folders': sorted(unmatched_folders),\n",
    "        'images_found': len(items)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf8be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Starting data collection from all datasets...')\n",
    "all_samples = []\n",
    "dataset_stats = {}\n",
    "audit_results = []\n",
    "\n",
    "for cfg in DATASETS:\n",
    "    audit = audit_dataset_structure(cfg)\n",
    "    audit_results.append(audit)\n",
    "    if not audit['exists'] or audit['total_images'] == 0:\n",
    "        logger.error(f\"Dataset audit failed for {cfg['hospital']} ({cfg['id']})\")\n",
    "        continue\n",
    "\n",
    "    logger.info(f\"Collecting data from {cfg['hospital']} ({cfg['id']})...\")\n",
    "    samples, collection_info = collect_images(cfg)\n",
    "    all_samples.extend(samples)\n",
    "\n",
    "    dataset_stats[cfg['hospital']] = {\n",
    "        'total_samples': len(samples),\n",
    "        'dataset_id': cfg['id'],\n",
    "        'location': HOSPITAL_CONFIGS[cfg['hospital']]['location'],\n",
    "        'specialty': HOSPITAL_CONFIGS[cfg['hospital']]['specialty'],\n",
    "        'class_distribution': {},\n",
    "        'unmatched_folders': collection_info['unmatched_folders']\n",
    "    }\n",
    "\n",
    "    if collection_info['unmatched_folders']:\n",
    "        logger.warning(\n",
    "            f\"Unmatched folders for {cfg['hospital']}: {collection_info['unmatched_folders']}\"\n",
    "        )\n",
    "\n",
    "    for sample in samples:\n",
    "        label = sample['label']\n",
    "        dataset_stats[cfg['hospital']]['class_distribution'][label] = \\\n",
    "            dataset_stats[cfg['hospital']]['class_distribution'].get(label, 0) + 1\n",
    "\n",
    "total_images = sum(a['total_images'] for a in audit_results)\n",
    "if total_images == 0 or len(all_samples) == 0:\n",
    "    raise ValueError(\n",
    "        'No images were discovered. Check dataset paths and class folder names.'\n",
    "    )\n",
    "\n",
    "logger.info(f'Total samples discovered: {len(all_samples)}')\n",
    "logger.info('Dataset statistics:')\n",
    "for hospital, stats in dataset_stats.items():\n",
    "    logger.info(f\"  {hospital}: {stats['total_samples']} samples\")\n",
    "    logger.info(f\"    Distribution: {stats['class_distribution']}\")\n",
    "\n",
    "with open(CACHE_DIR / 'dataset_stats.json', 'w') as f:\n",
    "    json.dump(dataset_stats, f, indent=2)\n",
    "logger.info('Saved dataset statistics to artifacts/dataset_stats.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(samples, seed=SEED, val_ratio=0.15, test_ratio=0.15):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    indices = np.arange(len(samples))\n",
    "    rng.shuffle(indices)\n",
    "    test_size = int(len(samples) * test_ratio)\n",
    "    val_size = int(len(samples) * val_ratio)\n",
    "    test_idx = indices[:test_size]\n",
    "    val_idx = indices[test_size:test_size + val_size]\n",
    "    train_idx = indices[test_size + val_size:]\n",
    "    return train_idx.tolist(), val_idx.tolist(), test_idx.tolist()\n",
    "\n",
    "logger.info('Creating train/val/test splits...')\n",
    "train_idx, val_idx, test_idx = create_splits(all_samples)\n",
    "splits = {\n",
    "    'train_idx': train_idx,\n",
    "    'val_idx': val_idx,\n",
    "    'test_idx': test_idx,\n",
    "    'split_date': datetime.now().isoformat()\n",
    "}\n",
    "with open(CACHE_SPLITS_FILE, 'w') as f:\n",
    "    json.dump(splits, f, indent=2)\n",
    "\n",
    "train_samples = [all_samples[i] for i in train_idx]\n",
    "val_samples = [all_samples[i] for i in val_idx]\n",
    "test_samples = [all_samples[i] for i in test_idx]\n",
    "\n",
    "logger.info(f'Train: {len(train_samples)} | Val: {len(val_samples)} | Test: {len(test_samples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c106db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e16cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samples[idx]\n",
    "        img = Image.open(item['path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = LABEL_MAP[item['label']]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b09ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BrainTumorDataset(train_samples, transform=train_transform)\n",
    "val_dataset = BrainTumorDataset(val_samples, transform=eval_transform)\n",
    "test_dataset = BrainTumorDataset(test_samples, transform=eval_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "logger.info('Data loaders created successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f0d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Initializing ResNet18 model...')\n",
    "model = models.resnet18(weights=None)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(LABEL_MAP))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "logger.info(f'Model initialized on {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdac453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac0c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, desc=''):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    class_labels = [IDX_TO_LABEL[i] for i in range(len(LABEL_MAP))]\n",
    "    report_dict = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=class_labels,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    per_class = {}\n",
    "    for label in class_labels:\n",
    "        metrics = report_dict.get(label, {})\n",
    "        per_class[label] = {\n",
    "            'precision': metrics.get('precision', 0.0),\n",
    "            'recall': metrics.get('recall', 0.0),\n",
    "            'f1': metrics.get('f1-score', 0.0),\n",
    "            'support': int(metrics.get('support', 0))\n",
    "        }\n",
    "\n",
    "    metrics = {\n",
    "        'loss': running_loss / len(loader.dataset),\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'macro_f1': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'macro_precision': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'macro_recall': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'per_class': per_class,\n",
    "        'confusion_matrix': confusion_matrix(y_true, y_pred).tolist(),\n",
    "        'report_text': classification_report(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            target_names=class_labels,\n",
    "            zero_division=0\n",
    "        )\n",
    "    }\n",
    "\n",
    "    if desc:\n",
    "        logger.info(\n",
    "            f'{desc} - Loss: {metrics[\"loss\"]:.4f}, '\n",
    "            f'Acc: {metrics[\"accuracy\"]:.4f}, '\n",
    "            f'F1: {metrics[\"macro_f1\"]:.4f}'\n",
    "        )\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17663d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('=' * 60)\n",
    "logger.info('Starting federated training simulation...')\n",
    "logger.info('=' * 60)\n",
    "\n",
    "training_history = []\n",
    "best_val_acc = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    logger.info(f'Epoch {epoch + 1}/{NUM_EPOCHS}')\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader)\n",
    "    logger.info(f'  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}')\n",
    "\n",
    "    val_metrics = evaluate(model, val_loader, desc='  Val')\n",
    "\n",
    "    training_history.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': train_loss,\n",
    "        'train_accuracy': train_acc,\n",
    "        'val_loss': val_metrics['loss'],\n",
    "        'val_accuracy': val_metrics['accuracy']\n",
    "    })\n",
    "\n",
    "    if val_metrics['accuracy'] > best_val_acc:\n",
    "        best_val_acc = val_metrics['accuracy']\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), ARTIFACTS_DIR / 'global_model.pth')\n",
    "        logger.info(f'  *** New best model saved (Acc: {best_val_acc:.4f}) ***')\n",
    "\n",
    "logger.info('=' * 60)\n",
    "logger.info(f'Training completed. Best validation accuracy: {best_val_acc:.4f} at epoch {best_epoch}')\n",
    "logger.info('=' * 60)\n",
    "\n",
    "with open(CACHE_DIR / 'training_history.json', 'w') as f:\n",
    "    json.dump(training_history, f, indent=2)\n",
    "logger.info('Saved training history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Loading best model for final evaluation...')\n",
    "model.load_state_dict(torch.load(ARTIFACTS_DIR / 'global_model.pth', map_location=DEVICE))\n",
    "\n",
    "test_metrics = evaluate(model, test_loader, desc='Test')\n",
    "\n",
    "logger.info('=' * 60)\n",
    "logger.info('FINAL TEST RESULTS:')\n",
    "logger.info(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "logger.info(f\"  Macro F1: {test_metrics['macro_f1']:.4f}\")\n",
    "logger.info(f\"  Macro Precision: {test_metrics['macro_precision']:.4f}\")\n",
    "logger.info(f\"  Macro Recall: {test_metrics['macro_recall']:.4f}\")\n",
    "logger.info('=' * 60)\n",
    "print('\\nPer-class Performance:')\n",
    "print(test_metrics['report_text'])\n",
    "\n",
    "with open(ARTIFACTS_DIR / 'label_map.json', 'w') as f:\n",
    "    json.dump(LABEL_MAP, f, indent=2)\n",
    "\n",
    "meta = {\n",
    "    'trained_at': datetime.now().isoformat(),\n",
    "    'num_classes': len(LABEL_MAP),\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'best_epoch': best_epoch,\n",
    "    'device': str(DEVICE),\n",
    "    'datasets': dataset_stats,\n",
    "    'total_samples': len(all_samples),\n",
    "    'train_samples': len(train_samples),\n",
    "    'val_samples': len(val_samples),\n",
    "    'test_samples': len(test_samples),\n",
    "    'metrics': {\n",
    "        'test_accuracy': test_metrics['accuracy'],\n",
    "        'avg_f1': test_metrics['macro_f1'],\n",
    "        'avg_precision': test_metrics['macro_precision'],\n",
    "        'avg_recall': test_metrics['macro_recall'],\n",
    "        'per_class': test_metrics['per_class'],\n",
    "        'confusion_matrix': test_metrics['confusion_matrix'],\n",
    "        'best_val_accuracy': best_val_acc\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(ARTIFACTS_DIR / 'model_meta.json', 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "logger.info(f'All artifacts saved to {ARTIFACTS_DIR}')\n",
    "logger.info('Training pipeline completed successfully!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
